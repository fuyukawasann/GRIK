{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6fc9a10-62db-4dea-91c9-35b742dc7868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a0a6184-5719-4b92-b6c7-03df3d510b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Path: /home/fuyukawa/IAP/Final_Project/GRIK/build/240607/Utils\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current Path: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8927b4c8-e3cd-4f62-aec9-acac2ac4c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_path = \"../Weights/Ver01/best_tiny_400_16.trt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3865c5cf-2686-4abf-9502-cee88d8e0ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "runtime = trt.Runtime(TRT_LOGGER)\n",
    "trt.init_libnvinfer_plugins(None, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d302aeb-1203-4543-a07e-997112f1616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(engine_path, 'rb') as f:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5186da-a4a8-429f-aa65-60c3fc896a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c578221",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs, bindings = [], [], []\n",
    "stream = cuda.Stream()\n",
    "for binding in engine:\n",
    "        size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n",
    "        dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "        host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "        device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "        bindings.append(int(device_mem))\n",
    "        if engine.binding_is_input(binding):\n",
    "            inputs.append({'host': host_mem, 'device': device_mem})\n",
    "        else:\n",
    "            outputs.append({'host': host_mem, 'device': device_mem})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa42203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "img = cv2.imread(\"../test05.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83075ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[cuda.memcpy_htod_async(inp['device'], inp['host'], stream) for inp in inputs]\n",
    "context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "[cuda.memcpy_dtoh_async(out['host'], out['device'], stream) for out in outputs]\n",
    "stream.synchronize()\n",
    "output = [out['host'] for out in outputs]\n",
    "print(\"Inference output: \", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IAP",
   "language": "python",
   "name": "iap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
